{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1836705",
   "metadata": {},
   "source": [
    "## <span style=\"color:pink\">**PROJETO FINAL DE MACHINE LEARNING 2022.1**</span>\n",
    "### **COLORIZAÇÃO DE IMAGENS BASEADA EM CAPAS DE ÁLBUNS**\n",
    "NICOLE SARVASI ALVES DA COSTA & KAÍQUE DOGNANI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b535c",
   "metadata": {},
   "source": [
    "Importação de bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e149c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "from skimage.color import rgb2hsv\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.color import hsv2rgb\n",
    "import PIL\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f106feb",
   "metadata": {},
   "source": [
    "### Criação do arquivo .pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1311f7a5",
   "metadata": {},
   "source": [
    "def RGB2X_Y():\n",
    "    with open('dados.pkl', 'rb') as file:\n",
    "        newDataSet = pickle.load(file)\n",
    "        file.close()\n",
    "    newDataSet = newDataSet[np.random.choice(newDataSet.shape[0], 5000), :, :, :]\n",
    "    newDataSet = newDataSet/255.0\n",
    "    for index, img in enumerate(newDataSet):\n",
    "        newDataSet[index] = rgb2hsv(img)\n",
    "    X_hsv = np.expand_dims(newDataSet[:,:,:,2], 3)\n",
    "    Y_hsv = newDataSet[:,:,:,:2]\n",
    "\n",
    "    return X_hsv, Y_hsv\n",
    "\n",
    "X_train, Y_train = RGB2X_Y()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ba3c1f",
   "metadata": {},
   "source": [
    "with open('dados_XY.pkl', 'wb') as file:\n",
    "    pickle.dump((X_train, Y_train), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dados_XY.pkl', 'rb') as file:\n",
    "    X_train, Y_train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9592da",
   "metadata": {},
   "source": [
    "### Pegando o arquivo de treino e diminuindo o número de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd931992",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:3500]\n",
    "Y_train = Y_train[:3500]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a2bfb2",
   "metadata": {},
   "source": [
    "## Definição do nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345575f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, input_shape=[150,150,1], kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.UpSampling2D(size=(2,2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.UpSampling2D(size=(2,2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(16, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.UpSampling2D(size=(2,2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(8, kernel_size=3, padding=\"same\", activation=\"linear\"),\n",
    "    keras.layers.UpSampling2D(size=(2,2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(16, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.UpSampling2D(size=(2,2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.UpSampling2D(size=(2,2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.UpSampling2D(size=(2,2)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Resizing(150, 150),\n",
    "    keras.layers.Conv2D(2, kernel_size=3, padding=\"same\", activation=\"linear\"), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0364fe",
   "metadata": {},
   "source": [
    "## Compilando o modelo e plotando informações sobre ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29028dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c7f3cc",
   "metadata": {},
   "source": [
    "## Treinando o modelo com uma função de EarlyStopping que para o treinamento quando chegamos nas medidas estabelecidas e para evitar que percamos qualquer evolução do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ed4df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    min_delta=0.0001,\n",
    "    patience=30,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=1000, batch_size=15, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c1b2f",
   "metadata": {},
   "source": [
    "## Aqui salvamos o modelo para futuramente podermos utilizá-lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1837415",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('MyModel_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb0ee1",
   "metadata": {},
   "source": [
    "## Abertura do modelo já salvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa2bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"MyModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37299d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c92b469",
   "metadata": {},
   "source": [
    "## Realizamos esta etapa para ter certeza de que as imagens que entram no preditor tenham 150X150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b782b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "path = \"C:\\\\Users\\\\Acer\\\\Pictures\\\\paramore.jpg\"\n",
    "file = PIL.Image.open(path)\n",
    "if file.size != (150,150):\n",
    "    file = file.resize((150,150))\n",
    "    file.save(path)\n",
    "    \n",
    "img = img_to_array(load_img(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405bc5df",
   "metadata": {},
   "source": [
    "## Transformação da imagem de RGB para HSV e divisão entre img_X que são as componentes H e S, e img_Y que é a componente V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47806baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hsv   = rgb2hsv(img/255.0)\n",
    "img_X_test = np.expand_dims(img_hsv[:,:,2],2)\n",
    "img_Y_test = img_hsv[:,:,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f5520",
   "metadata": {},
   "source": [
    "## Rodamos o modelo com a imagem de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_Y_pred = model.predict(np.array([img_X_test]))\n",
    "img_Y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8d0114",
   "metadata": {},
   "source": [
    "## Passamos a imagem de HSV para RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred_hsv = np.concatenate((img_Y_pred[0,:,:,:],img_X_test), axis=2)\n",
    "img_test_hsv = np.concatenate((img_Y_test,img_X_test), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3fa124",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"img_teste_hsv\",img_test_hsv.shape)\n",
    "print(\"img_pred_hsv\",img_pred_hsv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a65af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Imagem_Test = (255*hsv2rgb(img_test_hsv)).astype(np.uint8)\n",
    "Imagem_Pred = (255*hsv2rgb(img_pred_hsv)).astype(np.uint8)\n",
    "print(\"Imagem_Pred\",Imagem_Pred.shape)\n",
    "print(\"Imagem_Test\",Imagem_Test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bed9bb",
   "metadata": {},
   "source": [
    "## E finalmente plotamos a imagem final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f765318",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(Imagem_Test)\n",
    "plt.axis('off')\n",
    "plt.title(\"Test\")\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(Imagem_Pred)\n",
    "plt.axis('off')\n",
    "plt.title(\"Pred\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c28da407b5413b3940d87ecdae5ea8ce0c2929d84f560e9f5daaaa2573d53e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
