{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1836705",
   "metadata": {},
   "source": [
    "## <span style=\"color:pink\">**PROJETO FINAL DE MACHINE LEARNING 2022.1**</span>\n",
    "### **COLORIZAÇÃO DE IMAGENS BASEADA EM CAPAS DE ÁLBUNS**\n",
    "NICOLE SARVASI ALVES DA COSTA & KAÍQUE DOGNANI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b535c",
   "metadata": {},
   "source": [
    "Importação de bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e149c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "from skimage.color import rgb2hsv\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.color import hsv2rgb\n",
    "import PIL\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1c956",
   "metadata": {},
   "source": [
    "Importando a base de dados:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "418d3c51",
   "metadata": {},
   "source": [
    "dataset = os.listdir(\"Images\")\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2993503b",
   "metadata": {},
   "source": [
    "imgList = []\n",
    "for fileName in dataset:\n",
    "    imgList.append(img_to_array(load_img(\"Images\\\\\"+fileName)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9535c27f",
   "metadata": {},
   "source": [
    "X = np.array(imgList)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "023a5573",
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open(\"dados.pkl\", 'wb') as file:\n",
    "    pickle.dump(X,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ad466",
   "metadata": {},
   "source": [
    "Passando as imagens para HSV e dividindo-as por canal de cor, o X_hsv para o canal de valor (V) e o Y_hsv para os canais de matriz (H) e saturação (S)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be5177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB2X_Y():\n",
    "    with open(\"dados.pkl\", 'rb') as file:\n",
    "        newDataSet = pickle.load(file)\n",
    "        file.close()\n",
    "    newDataSet = newDataSet/255.0\n",
    "    for index, img in enumerate(newDataSet):\n",
    "        newDataSet[index] = rgb2hsv(img)\n",
    "    X_hsv = np.expand_dims(newDataSet[:,:,:,2], 3)\n",
    "    Y_hsv = newDataSet[:,:,:,:2]\n",
    "    return (X_hsv, Y_hsv)\n",
    "X_hsv, Y_hsv = RGB2X_Y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66725049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11957, 150, 150, 1)\n",
      "(11957, 150, 150, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_hsv.shape)\n",
    "print(Y_hsv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea2a883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55469435"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hsv.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9592da",
   "metadata": {},
   "source": [
    "Separando o conjunto de treino e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd931992",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_hsv, Y_hsv,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345575f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9565, 150, 150, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0364fe",
   "metadata": {},
   "source": [
    "Criando um modelo básico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29028dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(14, input_shape=[150,150,1], kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    keras.layers.Conv2D(2, kernel_size=3, padding=\"same\", activation=\"sigmoid\"),\n",
    "        \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80a27de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "567ed4df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "638/638 [==============================] - 34s 36ms/step - loss: 0.0979\n",
      "Epoch 2/30\n",
      "638/638 [==============================] - 21s 33ms/step - loss: 0.0972\n",
      "Epoch 3/30\n",
      "638/638 [==============================] - 21s 34ms/step - loss: 0.0969\n",
      "Epoch 4/30\n",
      "638/638 [==============================] - 22s 34ms/step - loss: 0.0967\n",
      "Epoch 5/30\n",
      "638/638 [==============================] - 21s 33ms/step - loss: 0.0963\n",
      "Epoch 6/30\n",
      "638/638 [==============================] - 21s 33ms/step - loss: 0.0959\n",
      "Epoch 7/30\n",
      "638/638 [==============================] - 23s 36ms/step - loss: 0.0955\n",
      "Epoch 8/30\n",
      "638/638 [==============================] - 22s 35ms/step - loss: 0.0954\n",
      "Epoch 9/30\n",
      "638/638 [==============================] - 20s 32ms/step - loss: 0.0953\n",
      "Epoch 10/30\n",
      "638/638 [==============================] - 21s 32ms/step - loss: 0.0952\n",
      "Epoch 11/30\n",
      "638/638 [==============================] - 19s 30ms/step - loss: 0.0951\n",
      "Epoch 12/30\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.0951\n",
      "Epoch 13/30\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.0950\n",
      "Epoch 14/30\n",
      "638/638 [==============================] - 19s 30ms/step - loss: 0.0949\n",
      "Epoch 15/30\n",
      "638/638 [==============================] - 19s 30ms/step - loss: 0.0949\n",
      "Epoch 16/30\n",
      "638/638 [==============================] - 20s 31ms/step - loss: 0.0948\n",
      "Epoch 17/30\n",
      "638/638 [==============================] - 19s 30ms/step - loss: 0.0947\n",
      "Epoch 18/30\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.0946\n",
      "Epoch 19/30\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.0945\n",
      "Epoch 20/30\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.0945\n",
      "Epoch 21/30\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.0944\n",
      "Epoch 22/30\n",
      "638/638 [==============================] - 19s 30ms/step - loss: 0.0944\n",
      "Epoch 23/30\n",
      "638/638 [==============================] - 20s 31ms/step - loss: 0.0943\n",
      "Epoch 24/30\n",
      "638/638 [==============================] - 19s 31ms/step - loss: 0.0943\n",
      "Epoch 25/30\n",
      "638/638 [==============================] - 19s 30ms/step - loss: 0.0942\n",
      "Epoch 26/30\n",
      "638/638 [==============================] - 19s 30ms/step - loss: 0.0942\n",
      "Epoch 27/30\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.0941\n",
      "Epoch 28/30\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.0941\n",
      "Epoch 29/30\n",
      "638/638 [==============================] - 19s 30ms/step - loss: 0.0940\n",
      "Epoch 30/30\n",
      "638/638 [==============================] - 19s 29ms/step - loss: 0.0940\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=30, batch_size=15)\n",
    "\n",
    "#score = model.evaluate(X_test, Y_test)\n",
    "# X_new = X_test[:10] # pretend we have new images\n",
    "# y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b782b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "file = PIL.Image.open(\"C:\\\\Users\\\\Acer\\\\Pictures\\\\paramore.jpg\")\n",
    "if file.size != (150,150):\n",
    "    file = file.resize((150,150))\n",
    "    file.save(\"C:\\\\Users\\\\Acer\\\\Pictures\\\\paramore.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63a1f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_to_array(load_img(\"C:\\\\Users\\\\Acer\\\\Pictures\\\\paramore.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47806baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hsv = rgb2hsv(img/255.0)\n",
    "img_final = np.expand_dims(img_hsv[:,:,2],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e90c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 150, 150, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 150, 1), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\"), but it was called on an input with incompatible shape (None, 150, 1, 1).\n",
      "5/5 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(img_final)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d71a65af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 3)\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "Imagem_Plotar = (hsv2rgb(np.concatenate((img_final, y_pred), axis=2)*255)).astype(np.uint8)\n",
    "\n",
    "print(Imagem_Plotar.shape)\n",
    "print(Imagem_Plotar.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f765318",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = PIL.Image.fromarray(Imagem_Plotar)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b774326c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeade78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
